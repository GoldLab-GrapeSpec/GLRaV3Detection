{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a34e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "\n",
    "import re, os, sys, getopt, time, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fiona\n",
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "from rasterio import Affine, MemoryFile\n",
    "from rasterio.enums import Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed91da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask() :\n",
    "\n",
    "    #masked_image = \n",
    "\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def apply_mask(self) :\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "345b82a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle_rf_model(rfm_pk_filepath) :\n",
    "    '''unpickle_rf_model loads and unpickles a random-forest model trained\n",
    "    on spectral residuals and disease incidence points.\n",
    "    rfm_pj - expected to be a filepath to a pickled (.pkl) random-forest model.\n",
    "\n",
    "    returns the unpickled random-forest model\n",
    "    '''\n",
    "    with open(rfm_pk_filepath, 'rb') as unpickled_model :\n",
    "        rf_model = pickle.load(unpickled_model)\n",
    "\n",
    "\n",
    "def clean_wl(src_wls) :\n",
    "    '''\n",
    "    '''\n",
    "    src_wls = src_wls.values()\n",
    "    wls = [re.findall('\\d+\\.\\d+',wl)[0] for wl in src_wls if len(re.findall('\\d+\\.\\d+',wl)) != 0]\n",
    "    float_wls = [round(float(wl),6) for wl in wls if wl.replace('.','',1).isdigit()]\n",
    "    \n",
    "    return sorted(float_wls)\n",
    "\n",
    "\n",
    "def remove_bb(wls) :\n",
    "    '''\n",
    "    '''\n",
    "    bbs = [[300,400],[1320,1430],[1800,1960],[2450,2600]]\n",
    "\n",
    "    np_wls = np.array(wls)\n",
    "    for bb in bbs :\n",
    "        np_wls = np_wls[(np_wls <= bb[0]) | (np_wls >= bb[1])]\n",
    "\n",
    "    return np_wls\n",
    "\n",
    "\n",
    "def null_nodata_pixels(src_img) :\n",
    "    band_count = meta['count'] # this might be bugged\n",
    "    cols = meta['width']\n",
    "    rows = meta['height']\n",
    "\n",
    "    nulled_image = np.empty((band_count,cols,rows), np.float64)\n",
    "\n",
    "    for band_position in range(band_count) :\n",
    "        band = self.spectra[band_position]\n",
    "        band[band == -9999] = np.nan\n",
    "        nulled_image[band_position,:,:] = band\n",
    "\n",
    "    return nulled_image\n",
    "\n",
    "\n",
    "def mask_imagery(poly_filepath, si_filepath) :\n",
    "    ''' Clips the spectra according to the boundaries of the polygon.\n",
    "    '''\n",
    "    with fiona.open(poly_filepath, \"r\") as geometries :\n",
    "        geom = [feature[\"geometry\"] for feature in geometries]\n",
    "\n",
    "    with rio.open(si_filepath) as src:\n",
    "        spectra, geog_transform = rio.mask.mask(src, geom, crop=True)\n",
    "        out_meta = src.meta\n",
    "        wls = clean_wl(src.tags()) # sorted list of wls; e.g [300.0, ... , 2500.0]\n",
    "        bbs = remove_bb(wls) # filtered list of wls; e.g. [405.0, ..., 2445]\n",
    "\n",
    "        out_meta.update({\n",
    "            \"height\" : spectra.shape[1],\n",
    "            \"width\" : spectra.shape[2],\n",
    "            \"transform\" : geog_transform\n",
    "            })\n",
    "\n",
    "    return inmemory(spectra, out_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f89762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_raster(image, meta, outputdir, output_filename=\"GLRaV\") :\n",
    "    ''' Apply RF model to the clipped and spectrally unmixed aviris image\n",
    "    '''\n",
    "    # To-Do\n",
    "    # 1. Dynamic filenames\n",
    "\n",
    "    output = ('%s%s_predictions.tif' % (outputdir, output_filename))\n",
    "    output_classes = ('%s%s_class_probability.tif' % (outputdir,output_filename))\n",
    "\n",
    "    classEncoder = LabelEncoder()\n",
    "\n",
    "    colWLHeaders = bbs.astype(str) # missing\n",
    "\n",
    "    cleanSpectra = image\n",
    "    b,h,w = cleanSpectra.shape # Band, Height, Width\n",
    "\n",
    "    # numpy-nd array > df\n",
    "    local_df = pd.DataFrame(cleanData.reshape([b,-1]).T, columns= colWLHeaders)\n",
    "    local_df_nn = local_df.dropna()\n",
    "\n",
    "    local_df_nn['classifications'] = rf_model.predict(local_df_nn[colWLHeaders])\n",
    "\n",
    "    # Class-Probabilities\n",
    "    class_probas = rf_model.predict_proba(local_df_nn[colWLHeaders])\n",
    "    class_count = len(class_probas[1])\n",
    "    classes = list(map(str,range(1,class_count+1)))\n",
    "\n",
    "    local_df_nn[classes] = class_probas\n",
    "\n",
    "    classEncoder.fit(local_df_nn['classifications'])\n",
    "    classValues = classEncoder.transform(local_df_nn['classifications'])\n",
    "    local_df_nn['classifications'] = classValues\n",
    "\n",
    "    local_df_j = local_df.join(local_df_nn[['classifications']+classes])\n",
    "\n",
    "    local_df_arr = np.array(local_df_j['classifications'])\n",
    "    output_raster = local_df_arr.reshape((1,h,w))\n",
    "\n",
    "    output_probs_raster = np.zeros((len(classes),h,w))\n",
    "    for i,c in enumerate(classes) :\n",
    "        local_df_probs_arr = np.array(local_df_j[c])\n",
    "        output_probs_raster[i] = local_df_probs_arr.reshape(1,h,w)\n",
    "\n",
    "    metadata.update({'count': 1,'drive':'GTiff'})\n",
    "    with rio.open(output,'w',**metadata) as dest :\n",
    "        dest.write(output_raster)\n",
    "\n",
    "    metadata.update({'count':len(classes),'drive':'GTiff'})\n",
    "    with rio.open(output_classes,'w',**metadata) as dest :\n",
    "        dest.write(output_probs_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fc0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smr_vegsoil(img, endmembers=\"endmembers.csv\") :\n",
    "    ''' unmix veg. vs soil\n",
    "    \n",
    "    To-Do:\n",
    "        1. set endmembers to be controllable via \n",
    "    '''\n",
    "    \n",
    "    local_bbs = np.in1d(image, self.bbs)\n",
    "\n",
    "    w = 1 # set unit sum constraint weight\n",
    "    D = image\n",
    "    d = np.reshape(D, [D.shape[0], D.shape[1]*D.shape[2]])\n",
    "    G = pd.read_csv(endmembers, sep=\"[,|\\t]\", header = None).to_numpy()\n",
    "    wavelength = G[:,0]\n",
    "    G = G[: ,1:G.shape[1]]\n",
    "\n",
    "    d = d[local_bbs]\n",
    "    G = G[local_bbs]\n",
    "\n",
    "    d_constraint = np.array(w*np.ones(d.shape[1]))\n",
    "    G_constraint = np.array(w*np.ones(G.shape[1]))\n",
    "\n",
    "    d = np.vstack([d,d_constraint])\n",
    "    G = np.vstack([G,G_constraint])\n",
    "\n",
    "    M_alt = np.linalg.inv(G.transpose().dot(G)).dot(G.transpose().dot(d))\n",
    "    M = np.reshape(M_alt, [d.shape[0],D.shape[1],D.shape[2]])\n",
    "    #mixtureResidual_alt = d-(G.dot(np.linalg.inv(G.transpose().dot(G)).dot(G.transpose()))).dot(d)\n",
    "    #smr = np.reshape(mixtureResidual_alt,[d.shape[0],D.shape[1],D.shape[2]])\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac969a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model_filepath, si_filepath, poly_filepath, outputdir) :\n",
    "    '''\n",
    "    '''\n",
    "    # Step 1: unpickle the model\n",
    "    model = unpickle_rf_model(model_filepath)\n",
    "    \n",
    "    # Step 2: Clip AVIRIS-NG Imagery\n",
    "    vineyard_si = mask_imagery(poly_filepath, si_filepath)\n",
    "    \n",
    "    return vineyard_si\n",
    "    # Step 3: remove -9999s from Imagery and replace with NA\n",
    "        \n",
    "    # Step 3: calculate spectral mixture residual weights\n",
    "    \n",
    "    # Step 4: Generate vegetation mask\n",
    "    \n",
    "    # Step 5: Apply vegetation mask to Step 3 output\n",
    "    \n",
    "    # Step 6: Apply model to SMR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a05518d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use context manager so DatasetReader and MemoryFile get cleaned up automatically\n",
    "@contextmanager\n",
    "def inmemory_writer(numpy_arr, meta):\n",
    "    with MemoryFile() as memfile:\n",
    "        with memfile.open(**meta) as dataset: # Open as DatasetWriter\n",
    "            dataset.write(numpy_arr, driver=\"ENVI\")\n",
    "            #return dataset\n",
    "            #del numpy_arr\n",
    "        with memfile.open() as dataset:  # Reopen as DatasetReader\n",
    "            yield dataset  # Note yield not return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75db4f10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'memfile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_765031/3130885530.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mMemoryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mmemfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'memfile' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = '/media/ferg/IronWolf_10TB/'\n",
    "m = 'RFm_smr_H_SyAsy.pk'\n",
    "si = data_dir + 'AVIRIS_NG/brdf_rfl/ang20200918t210249_rfl_topo_brdf'\n",
    "poly = data_dir + 'Thesis/data/polys/vineyard_polys/VineyardID_LT_124.geojson'\n",
    "o = './'\n",
    "\n",
    "current_step = pipeline(m, si, poly, o)\n",
    "\n",
    "with MemoryFile() as cs:\n",
    "    with memfile.open() as dataset :\n",
    "        print(dataset.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42fbc78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
