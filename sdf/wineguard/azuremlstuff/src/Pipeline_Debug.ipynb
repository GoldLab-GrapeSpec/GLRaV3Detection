{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a34e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "import re, os, sys, getopt, time, pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fiona\n",
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "from rasterio import Affine, MemoryFile\n",
    "from rasterio.enums import Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed91da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask() :\n",
    "\n",
    "    #masked_image = \n",
    "\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "def apply_mask(si, mask_raster) :\n",
    "    \n",
    "    mask = generate_mask(si)\n",
    "    \n",
    "    bands = si.shape[0]\n",
    "    rows = mask.shape[0]\n",
    "    cols = mask.shape[1]\n",
    "\n",
    "    masked_bands_matrix = np.empty((band_count,rows,cols,), np.float32)\n",
    "\n",
    "    for band in range(bands):\n",
    "        applied_mask = raster[band] * mask\n",
    "        applied_mask[applied_mask == 0] = np.nan\n",
    "        masked_bands_matrix[band,:,:] = applied_mask\n",
    "\n",
    "    return masked_si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "345b82a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle_rf_model(rfm_pk_filepath) :\n",
    "    '''unpickle_rf_model loads and unpickles a random-forest model trained\n",
    "    on spectral residuals and disease incidence points.\n",
    "    rfm_pj - expected to be a filepath to a pickled (.pkl) random-forest model.\n",
    "\n",
    "    returns the unpickled random-forest model\n",
    "    '''\n",
    "    with open(rfm_pk_filepath, 'rb') as unpickled_model :\n",
    "        rf_model = pickle.load(unpickled_model)\n",
    "\n",
    "\n",
    "def clean_wl(src_wls) :\n",
    "    '''\n",
    "    '''\n",
    "    src_wls = src_wls.values()\n",
    "    wls = [re.findall('\\d+\\.\\d+',wl)[0] for wl in src_wls if len(re.findall('\\d+\\.\\d+',wl)) != 0]\n",
    "    float_wls = [round(float(wl),6) for wl in wls if wl.replace('.','',1).isdigit()]\n",
    "    \n",
    "    return sorted(float_wls)\n",
    "\n",
    "\n",
    "def remove_bb(wls) :\n",
    "    '''\n",
    "    '''\n",
    "    bbs = [[300,400],[1320,1430],[1800,1960],[2450,2600]]\n",
    "\n",
    "    np_wls = np.array(wls)\n",
    "    for bb in bbs :\n",
    "        np_wls = np_wls[(np_wls <= bb[0]) | (np_wls >= bb[1])]\n",
    "\n",
    "    return np_wls\n",
    "\n",
    "\n",
    "def null_nodata_pixels(src_img) :\n",
    "    band_count, cols, rows = src_img.shape\n",
    "\n",
    "    nulled_image = np.empty((band_count,cols,rows), np.float64)\n",
    "\n",
    "    for band_position in range(band_count) :\n",
    "        band = src_img[band_position]\n",
    "        band[band == -9999] = np.nan\n",
    "        nulled_image[band_position,:,:] = band\n",
    "\n",
    "    return nulled_image\n",
    "\n",
    "\n",
    "def mask_imagery(poly_filepath, si_filepath) :\n",
    "    ''' Clips the spectra according to the boundaries of the polygon.\n",
    "    '''\n",
    "    with fiona.open(poly_filepath, \"r\") as geometries :\n",
    "        geom = [feature[\"geometry\"] for feature in geometries]\n",
    "\n",
    "    with rio.open(si_filepath) as src:\n",
    "        spectra, geog_transform = rio.mask.mask(src, geom, crop=True)\n",
    "        out_meta = src.meta\n",
    "        wls = clean_wl(src.tags()) # sorted list of wls; e.g [300.0, ... , 2500.0]\n",
    "        bbs = remove_bb(wls) # filtered list of wls; e.g. [405.0, ..., 2445]\n",
    "\n",
    "        out_meta.update({\n",
    "            \"height\" : spectra.shape[1],\n",
    "            \"width\" : spectra.shape[2],\n",
    "            \"transform\" : geog_transform\n",
    "            })\n",
    "    \n",
    "    return spectra, out_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3fc0a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smr_vegsoil(si, endmembers=\"endmembers.csv\") :\n",
    "    ''' unmix veg. vs soil\n",
    "    '''\n",
    "    \n",
    "    local_bbs = np.in1d(si, bbs)\n",
    "\n",
    "    w = 1 # set unit sum constraint weight\n",
    "    D = si\n",
    "    d = np.reshape(D, [D.shape[0], D.shape[1]*D.shape[2]])\n",
    "    G = pd.read_csv(endmembers, sep=\"[,|\\t]\", header = None).to_numpy()\n",
    "    wavelength = G[:,0]\n",
    "    G = G[: ,1:G.shape[1]]\n",
    "\n",
    "    d = d[local_bbs]\n",
    "    G = G[local_bbs]\n",
    "\n",
    "    d_constraint = np.array(w*np.ones(d.shape[1]))\n",
    "    G_constraint = np.array(w*np.ones(G.shape[1]))\n",
    "\n",
    "    d = np.vstack([d,d_constraint])\n",
    "    G = np.vstack([G,G_constraint])\n",
    "\n",
    "    M_alt = np.linalg.inv(G.transpose().dot(G)).dot(G.transpose().dot(d))\n",
    "    M = np.reshape(M_alt, [d.shape[0],D.shape[1],D.shape[2]])\n",
    "    #mixtureResidual_alt = d-(G.dot(np.linalg.inv(G.transpose().dot(G)).dot(G.transpose()))).dot(d)\n",
    "    #smr = np.reshape(mixtureResidual_alt,[d.shape[0],D.shape[1],D.shape[2]])\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f89762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_raster(image, meta, outputdir, output_filename=\"GLRaV\") :\n",
    "    ''' Apply RF model to the clipped and spectrally unmixed aviris image\n",
    "    '''\n",
    "    # To-Do\n",
    "    # 1. Dynamic filenames\n",
    "\n",
    "    output = ('%s%s_predictions.tif' % (outputdir, output_filename))\n",
    "    output_classes = ('%s%s_class_probability.tif' % (outputdir,output_filename))\n",
    "\n",
    "    classEncoder = LabelEncoder()\n",
    "\n",
    "    colWLHeaders = bbs.astype(str) # missing\n",
    "\n",
    "    cleanSpectra = image\n",
    "    b,h,w = cleanSpectra.shape # Band, Height, Width\n",
    "\n",
    "    # numpy-nd array > df\n",
    "    local_df = pd.DataFrame(cleanData.reshape([b,-1]).T, columns= colWLHeaders)\n",
    "    local_df_nn = local_df.dropna()\n",
    "\n",
    "    local_df_nn['classifications'] = rf_model.predict(local_df_nn[colWLHeaders])\n",
    "\n",
    "    # Class-Probabilities\n",
    "    class_probas = rf_model.predict_proba(local_df_nn[colWLHeaders])\n",
    "    class_count = len(class_probas[1])\n",
    "    classes = list(map(str,range(1,class_count+1)))\n",
    "\n",
    "    local_df_nn[classes] = class_probas\n",
    "\n",
    "    classEncoder.fit(local_df_nn['classifications'])\n",
    "    classValues = classEncoder.transform(local_df_nn['classifications'])\n",
    "    local_df_nn['classifications'] = classValues\n",
    "\n",
    "    local_df_j = local_df.join(local_df_nn[['classifications']+classes])\n",
    "\n",
    "    local_df_arr = np.array(local_df_j['classifications'])\n",
    "    output_raster = local_df_arr.reshape((1,h,w))\n",
    "\n",
    "    output_probs_raster = np.zeros((len(classes),h,w))\n",
    "    for i,c in enumerate(classes) :\n",
    "        local_df_probs_arr = np.array(local_df_j[c])\n",
    "        output_probs_raster[i] = local_df_probs_arr.reshape(1,h,w)\n",
    "\n",
    "    metadata.update({'count': 1,'drive':'GTiff'})\n",
    "    with rio.open(output,'w',**metadata) as dest :\n",
    "        dest.write(output_raster)\n",
    "\n",
    "    metadata.update({'count':len(classes),'drive':'GTiff'})\n",
    "    with rio.open(output_classes,'w',**metadata) as dest :\n",
    "        dest.write(output_probs_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac969a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model_filepath, si_filepath, poly_filepath, outputdir) :\n",
    "    '''\n",
    "    '''\n",
    "    # Step 1: unpickle the model\n",
    "    model = unpickle_rf_model(model_filepath)\n",
    "    \n",
    "    # Step 2: Clip AVIRIS-NG Imagery\n",
    "    vineyard_si, meta = mask_imagery(poly_filepath, si_filepath)\n",
    "    # Step 3: remove -9999s from Imagery and replace with NA\n",
    "    vineyard_si = null_nodata_pixels(vineyard_si)\n",
    "    \n",
    "    # Step 3: calculate spectral mixture residual weights\n",
    "    vineyard_si = smr_vegsoil(vineyard_si)\n",
    "    return vineyard_si, meta\n",
    "    \n",
    "    # Step 4: Generate vegetation mask\n",
    "    \n",
    "    # Step 5: Apply vegetation mask to Step 3 output\n",
    "    \n",
    "    # Step 6: Apply model to SMR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4d9c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use context manager so DatasetReader and MemoryFile get cleaned up automatically\n",
    "@contextmanager\n",
    "def inmemory_writer(numpy_arr, meta):\n",
    "    with MemoryFile() as memfile:\n",
    "        with memfile.open(**meta) as dataset: # Open as DatasetWriter\n",
    "            dataset.write(numpy_arr)\n",
    "            return dataset\n",
    "        #    del numpy_arr\n",
    "        #with memfile.open() as dataset: # Reopen as DatasetReader\n",
    "        #    yield dataset # Note yield not return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75db4f10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_89684/971460844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#with inmemory_writer(si, out_meta) as dataset :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_89684/1650688479.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(model_filepath, si_filepath, poly_filepath, outputdir)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Step 3: calculate spectral mixture residual weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mvineyard_si\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmr_vegsoil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvineyard_si\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvineyard_si\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_89684/1139093016.py\u001b[0m in \u001b[0;36msmr_vegsoil\u001b[0;34m(si, endmembers)\u001b[0m\n\u001b[1;32m      6\u001b[0m     '''\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlocal_bbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# set unit sum constraint weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "data_dir = '/media/ferg/IronWolf_10TB/'\n",
    "m = 'RFm_smr_H_SyAsy.pk'\n",
    "si = data_dir + 'AVIRIS_NG/brdf_rfl/ang20200918t210249_rfl_topo_brdf'\n",
    "poly = data_dir + 'Thesis/data/polys/vineyard_polys/VineyardID_LT_124.geojson'\n",
    "o = './'\n",
    "\n",
    "si, out_meta = pipeline(m, si, poly, o)\n",
    "\n",
    "#with inmemory_writer(si, out_meta) as dataset :\n",
    "#    print(dataset.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e578f422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3c9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "si.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42fbc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c769b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
